%-------------------------
% Resume â€” Akhil Shekkari
% Targeted: AI/ML Research Engineer roles at top labs
%------------------------

\documentclass[letterpaper,11pt]{article}

\usepackage{latexsym}
\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage{marvosym}
\usepackage[usenames,dvipsnames]{color}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}
\input{glyphtounicode}
\usepackage[a4paper, top=0.3in, left=0.5in, right=0.5in, bottom=0.3in]{geometry}

\pagestyle{fancy}
\fancyhf{}
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

\urlstyle{same}
\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}

% Sections formatting
\titleformat{\section}{
  \vspace{-6pt}\scshape\raggedright\large
}{}{0em}{}[\color{black}\titlerule \vspace{-6pt}]

% ATS parsable
\pdfgentounicode=1

%-------------------------
% Custom commands
\newcommand{\resumeItem}[1]{
  \item\small{
    {#1 \vspace{-3pt}}
  }
}

\newcommand{\resumeSubheadingSingle}[2]{
  \vspace{-2pt}\item
    \begin{tabular*}{0.97\textwidth}[t]{l@{\extracolsep{\fill}}r}
      \textbf{#1} & #2 \\
    \end{tabular*}\vspace{-7pt}
}

\newcommand{\resumeProjectHeading}[2]{
    \vspace{-2pt}\item
    \begin{tabular*}{0.97\textwidth}[t]{l@{\extracolsep{\fill}}r}
      #1 & #2 \\
    \end{tabular*}\vspace{-7pt}
}

\renewcommand\labelitemii{$\vcenter{\hbox{\tiny$\bullet$}}$}

\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=0.15in, label={}]}
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}[leftmargin=0.15in]}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-5pt}}

%-------------------------------------------
\begin{document}

%----------HEADING----------
\begin{center}
    \textbf{\Huge \scshape Akhil Shekkari} \\ \vspace{1pt}
    \small
    \href{https://shekkari1999.github.io}{Portfolio} \textbar\
    \href{https://github.com/shekkari1999}{GitHub} \textbar\
    \href{https://www.linkedin.com/in/akhilshekkari/}{LinkedIn} \textbar\
    \href{mailto:shekkari.akhil@gmail.com}{shekkari.akhil@gmail.com} \textbar\
    +1 (425) 426-8292
\end{center}
\vspace{-0.4cm}

%-----------SUMMARY-----------
\section{Summary}
\vspace{2pt}
\begin{itemize}[leftmargin=0.15in, label={}]
  \small{
    \item \textbf{AI Engineer} with 3+ years of industry experience building and deploying \textbf{production LLM systems}. Specialized in Agents, post-training, and inference optimization, with a focus on evaluation and scalable system design.
  }
\end{itemize}
\vspace{-0.45cm}

%-----------EXPERIENCE-----------
\section{Experience}
\vspace{2pt}
  \resumeSubHeadingListStart

    \resumeSubheadingSingle
      {AI Engineer \textbar\ Atrium \textbar\ Silver Spring, USA}{June 2025 - August 2025}
      \resumeItemListStart
        \resumeItem{Automated Statistical Analysis Plan  generation from clinical trial documents for \textbf{Pfizer's team}, reducing drafting time by up to \textbf{60\%}.}
        \resumeItem{Evaluated knowledge graphs, naive chunking, and semantic chunking strategies; benchmarked \textbf{embedding models} (OpenAI) and \textbf{hybrid retrieval} (dense + BM25 sparse), and selected the best-performing RAG configuration on internal test sets.}
        \resumeItem{Built a custom \textbf{LLM-as-a-Judge} evaluation system with structured rubrics scoring completeness, guideline adherence, and hallucination detection against ground truth SAPs, achieving \textbf{82\% precision} and \textbf{78\% recall}.}
        \resumeItem{Conducted multiple prompt experiments improving generation consistency by \textbf{20\%} and reducing manual revision cycles by \textbf{30\%}.}
      \resumeItemListEnd

    \vspace{2pt}

    \resumeSubheadingSingle
      {Machine Learning Engineer \textbar\ Tezo \textbar\ India}
      {July 2021 - July 2024}
      \resumeItemListStart
        \resumeItem{ Built a \textbf{RAG} powered chatbot over SharePoint repositories, giving \textbf{200+} employees a unified search interface across \textbf{1,000+} internal documents with sub-second retrieval.}
        \resumeItem{Engineered a  \textbf{semantic search} pipeline (embeddings + vector DB) reducing document lookup time by \textbf{60\%}, and added LLM-based summarization cutting manager review time by \textbf{35\%}.}
        \resumeItem{Optimized \textbf{chunking} and \textbf{retrieval} by benchmarking chunk sizes, overlap strategies, and hybrid search, improving answer relevance and reducing hallucination rates across document types.}
        \resumeItem{Built an \textbf{evaluation} pipeline to measure RAG output quality tracking faithfulness, retrieval relevance, and hallucination rates across queries, enabling data-driven iteration on the retrieval and generation stages.}
        \resumeItem{\textbf{Trained ML models} for insurance policy scoring and fraud detection, improving fraud recall by \textbf{15\%} and enabling earlier intervention across the claims pipeline.}
      \resumeItemListEnd

  \resumeSubHeadingListEnd
\vspace{-0.45cm}

%-----------PROJECTS-----------
\section{Projects}
\vspace{-0.5pt}
\resumeSubHeadingListStart

  \resumeProjectHeading
      {\textbf{RL Post-Training for LLM Reasoning at Scale} {\small\href{https://github.com/shekkari1999/reasoning}{GitHub}}}{2025}
      \resumeItemListStart
        \resumeItem{Post-trained \textbf{Qwen-2.5} into a reasoning model in raw PyTorch, reproducing a DeepSeek-R1-style pipeline: supervised fine-tuning on chain-of-thought traces followed by \textbf{GRPO} reinforcement learning to elicit long-horizon reasoning without a learned critic.}
        \resumeItem{Scaled \textbf{RL} training across multiple GPUs using \textbf{FSDP} with mixed precision and gradient accumulation; overlapped rollout generation and policy updates via \textbf{NCCL} to maximize hardware utilization.}
        \resumeItem{\textbf{Profiled} distributed training with \textbf{Nsight Systems} and \textbf{Nsight Compute}, diagnosing all-reduce communication stalls and CUDA kernel launch overhead to reduce idle time and improve GPU efficiency.}
        \resumeItem{\textbf{Evaluated performance} on GSM8K and MATH using a SymPy-based symbolic equivalence harness, observing consistent gains over the base model after SFT and GRPO.}
      \resumeItemListEnd

  \vspace{2pt}

  \resumeProjectHeading
    {\textbf{LLM Inference Engine from Scratch} {\small\href{https://github.com/shekkari1999/mini-Inference-engine-from-scratch}{GitHub}}}{2025}
    \resumeItemListStart
      \resumeItem{Built a modular \textbf{inference engine} with interchangeable attention backends: naive O(T\textsuperscript{2}), streaming O(T) with online softmax, and a \textbf{Triton}-fused FlashAttention kernel with tiled memory access.}
      \resumeItem{Implemented \textbf{paged KV}-cache with on-demand allocation, reducing peak memory from O(T\textsuperscript{2}) to O(T) compared to contiguous caching.}
      \resumeItem{Benchmarked \textbf{prefill} and \textbf{decode} throughput across \textbf{4K--16K} context lengths, quantifying Triton kernel-fusion speedups over Python-level implementations.}
      \resumeItem{Profiled GPU kernels to characterize memory-bound vs compute-bound regimes and measured global memory throughput relative to \textbf{roofline} limits.}
    \resumeItemListEnd

  \vspace{2pt}

  \resumeProjectHeading
    {\textbf{AI Agent Framework} {\small\href{https://github.com/shekkari1999/Agents}{GitHub}}}{2025}
    \resumeItemListStart
      \resumeItem{Built a \textbf{multi-step reasoning agent from scratch} with function calling, \textbf{MCP} integration for external tool servers, Pydantic-validated structured outputs, sliding-window memory with compaction, and evaluated on the \textbf{GAIA} benchmark.}
    \resumeItemListEnd

\resumeSubHeadingListEnd
\vspace{-0.45cm}

%-----------SKILLS-----------
\section{Technical Skills}
\vspace{2pt}
\begin{itemize}[leftmargin=0.15in, label={}]
  \small{
    \item \textbf{Languages \& Frameworks:} Python, PyTorch, Triton, SQL, Pydantic, FastAPI, Gradio, LangChain, LlamaIndex
    \vspace{-0.2cm}
    \item \textbf{ML \& Training:} LoRA/QLoRA, FSDP, Hugging Face Transformers, Unsloth, W\&B, ClearML, Scikit-learn
    \vspace{-0.2cm}
    \item \textbf{Infrastructure:} Docker, Kubernetes, AWS SageMaker, Azure ML, Snowflake, GitHub Actions, CI/CD
  }
\end{itemize}
\vspace{-0.45cm}

%-----------EDUCATION-----------
\section{Education}
\vspace{2pt}
\begin{itemize}[leftmargin=0.15in, label={}]
  \small{
    \item \textbf{University of Maryland, College Park} \hfill Expected May 2026 \\
          Master of Science in Applied Machine Learning \\
          \textbf{Coursework:} Deep Learning, NLP, Advanced ML, Reinforcement Learning, Optimization, Probability \& Statistics
  }
\end{itemize}

%-------------------------------------------
\end{document}