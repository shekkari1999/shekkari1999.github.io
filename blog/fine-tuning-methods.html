<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fine-tuning Methods in LLMs: Part 1 | Akhil Shekkari</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css">
    <link rel="stylesheet" href="../css/styles.css">
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
</head>
<body>
    <a href="../blogs.html" class="back-link">← Back to Blog</a>

    <div class="newsletter-signup">
        <h4>Stay Updated</h4>
        <p>Get notified about new articles on AI and Deep Learning</p>
        <form id="newsletterForm" action="https://formspree.io/f/akhil.masters21@gmail.com" method="POST">
            <input type="email" name="email" placeholder="Your email address" required>
            <button type="submit">Subscribe</button>
        </form>
    </div>

    <article>
        <h1>Fine-tuning Methods in LLMs: Part 1</h1>
        
        <p class="blog-meta">Mar 14th, 2024 · 20 min read</p>
        <hr class="section-break">

        <p>
            This blog explores various fine-tuning methods for Large Language Models. For a better understanding 
            of the motivation behind these techniques, I recommend first reading my article on 
            <a href="Memory-optimization.html">Memory Optimization in Deep Learning</a>.
        </p>

        <h2>Understanding Fine-tuning vs Training</h2>
        
        <div class="note-block">
            <p>
                <strong>Key Distinction:</strong> Training involves starting with random weights, while fine-tuning 
                starts with pre-trained model weights. This fundamental difference shapes our approach to model adaptation.
            </p>
        </div>

        <h2>The Memory Challenge</h2>
        
        <p>
            When running large models on available hardware, you typically have two main options:
        </p>
        
        <div class="code-example">
Options for Running Large Models:

1. Reduce Memory Footprint
   • Quantization
   • Parameter-efficient methods
   • Gradient checkpointing

2. Distribute Computation
   • CPU offloading with DeepSpeed
   • Model parallelism
   • Pipeline parallelism</div>

        <h2>Evolution of Fine-tuning Approaches</h2>

        <h3>1. Full Fine-tuning</h3>
        
        <div class="diagram-container">
            <img src="../images/fine-tuning-1/ft-1.png" alt="Full Fine-tuning Diagram" class="diagram">
            <div class="diagram-caption">Figure 1: Traditional full fine-tuning approach where all model parameters are updated</div>
        </div>

        <p>
            In the early days of deep learning, when models had fewer parameters, full fine-tuning was the standard approach. 
            This method updates all model weights during the adaptation process.
        </p>

        <h3>2. Partial Fine-tuning</h3>
        
        <p>
            As models grew larger, researchers began experimenting with partial fine-tuning, freezing about 10% of the model 
            weights. While this reduced memory footprint, the performance benefits were limited. Meaningful improvements 
            typically required fine-tuning at least 30% of the model parameters.
        </p>

        <blockquote>
            <p>
                The critical question emerged: Could we achieve significant performance improvements while updating 
                only a tiny fraction of parameters? This led to the development of Parameter-Efficient Fine-Tuning (PEFT) methods.
            </p>
        </blockquote>

        <h3>Parameter-Efficient Fine-Tuning (PEFT)</h3>
        
        <p>
            The core idea behind PEFT is strategic: introduce small trainable neural networks called "adapters" 
            at carefully selected locations within the model. These adapters act as learnable interfaces 
            between the model's frozen layers. During fine-tuning, the original pre-trained weights remain 
            unchanged, and only these adapter parameters are updated, making the process highly efficient.
        </p>
        
        <div class="comparison-table">
            <div class="comparison-column">
                <h5>Advantages</h5>
                <ul>
                    <li>Parameter Efficient: Requires only a small fraction of trainable parameters</li>
                    <li>Sample Efficient: Needs fewer examples for effective fine-tuning</li>
                    <li>Memory Efficient: Significantly reduced memory footprint</li>
                </ul>
            </div>
            <div class="comparison-column">
                <h5>Limitations</h5>
                <ul>
                    <li>Increased Inference Latency: Additional computation overhead during forward pass</li>
                    <li>Architecture Modifications: Requires changes to model structure</li>
                </ul>
            </div>
        </div>

        <div class="diagram-container">
            <img src="../images/fine-tuning-1/ft-2.png" alt="PEFT Methods Overview" class="diagram">
            <div class="diagram-caption">Figure 2: Overview of Parameter-Efficient Fine-Tuning approaches</div>
        </div>

        <h3>Understanding Prompt-Based Methods</h3>
        
        <h4>Hard Prompting</h4>
        <div class="code-example">
 Example of Hard Prompting:
 
 Input: "How to make a delicious pizza?"
 
 Hard Prompt: "As an expert chef, provide step-by-step instructions for making a delicious pizza:"
 
 This is a discrete text prompt that guides the model's behavior but cannot be optimized during training.</div>
 
        <h4>Soft Prompting</h4>
        <div class="code-example">
 Soft Prompt Example:
 
 Instead of discrete text, we use trainable embeddings:
 [0.23, -0.45, 0.89, ...] → Trained to represent "summarize"
 [0.67, 0.12, -0.34, ...] → Trained to represent "explain"
 
 These continuous vectors are learned during fine-tuning to optimize task performance.</div>
 
        <h4>Key Prompt-Based Methods</h4>
        <ul>
            <li><strong>Prefix Tuning:</strong> Adds trainable continuous tokens before specific layers</li>
            <li><strong>Prompt Tuning:</strong> Prepends trainable embeddings to the input</li>
            <li><strong>P-Tuning:</strong> Introduces trainable prompts at multiple positions</li>
        </ul>

        <div class="note-block">
            <strong>Understanding Soft Prompts:</strong>
            <p>
                Think of soft prompts as the model learning a "language" of its own. For example, when fine-tuned 
                on summarization tasks, the soft prompts might encode patterns that help the model recognize key 
                information and generate concise outputs. While we can't "read" these embeddings directly, their 
                effect on the model's behavior is measurable and consistent.
            </p>
        </div>

        <div class="interaction-section">
            <div class="like-section">
                <button id="likeButton" class="like-button">
                    <span class="heart-icon">♥</span>
                    <span class="like-count">0</span> Likes
                </button>
            </div>
            
            <div class="comment-section">
                <h4>Comments</h4>
                <form id="commentForm" class="comment-form">
                    <div class="form-group">
                        <input type="text" id="commentName" placeholder="Your name" required>
                    </div>
                    <div class="form-group">
                        <textarea id="commentText" placeholder="Share your thoughts..." required></textarea>
                    </div>
                    <button type="submit">Post Comment</button>
                </form>
                
                <div id="comments" class="comments-list">
                    <!-- Comments will be dynamically added here -->
                </div>
            </div>
        </div>
    </article>

    <footer>
        <p>© 2024 Akhil Shekkari · <a href="https://github.com/shekkari1999">GitHub</a></p>
    </footer>

    <script>
        // Like and comment functionality (same as Memory-optimization.html)
    </script>
</body>
</html> 

(say something like those methods are kinda less popular than lora)
Now Lets explore and understand Lora