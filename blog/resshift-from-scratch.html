<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>From Scratch Implementation of ResShift Paper for Image Super-Resolution | Akhil Shekkari</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css">
    <link rel="stylesheet" href="../css/styles.css">
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
    <style>
        .disclaimer {
            background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%);
            border-radius: 12px;
            padding: 16px;
            margin: 20px 0;
            text-align: center;
            box-shadow: 0 4px 16px rgba(255, 234, 167, 0.3);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }

        .disclaimer p {
            margin: 0;
            color: #2d3436;
            font-size: 0.95em;
            font-weight: 500;
        }

        .placeholder-notice {
            background: linear-gradient(135deg, #e3f2fd 0%, #e1bee7 100%);
            border-radius: 12px;
            padding: 30px;
            margin: 40px 0;
            text-align: center;
            border: 2px dashed #667eea;
        }

        .placeholder-notice h3 {
            color: #667eea;
            margin-bottom: 15px;
        }

        .placeholder-notice p {
            color: #555;
            line-height: 1.6;
            font-size: 1.1em;
        }
    </style>
</head>
<body>
    <article>
        <a href="../blogs.html" class="back-link">‚Üê Back to Blogs</a>
        
        <h1>From Scratch Implementation of ResShift Paper for Image Super-Resolution</h1>
        
        <div class="blog-meta">
            Coming Soon ¬∑ Diffusion Models ¬∑ Computer Vision ¬∑ Deep Learning
        </div>

        <div class="placeholder-notice">
            <h3>üöß Blog Post Coming Soon</h3>
            <p>
                This blog post will dive deep into my complete from-scratch implementation of the ResShift paper 
                for image super-resolution. I'll explain how I built an efficient diffusion-based super-resolution 
                model using a U-Net architecture with Swin Transformer blocks, including the residual shifting 
                mechanism that reduces diffusion steps to just 15 timesteps. The post will cover architecture 
                design, training on DIV2K dataset, and lessons learned from implementing this state-of-the-art 
                approach to image enhancement.
            </p>
            <p style="margin-top: 15px; font-style: italic;">
                Check out the implementation: <a href="https://github.com/shekkari1999/DiffusionSR" target="_blank" style="color: #667eea;">GitHub Repository</a>
            </p>
            <p style="margin-top: 15px; font-style: italic;">
                Stay tuned for detailed explanations, code walkthroughs, and practical insights!
            </p>
        </div>

        <div class="disclaimer">
            <p>
                <strong>Note:</strong> This is a placeholder for a future blog post. 
                The full content will be published soon.
            </p>
        </div>
    </article>

    <footer>
        <p>¬© 2025 Akhil Shekkari ¬∑ <a href="https://github.com/shekkari1999">GitHub</a> ¬∑ <a href="https://www.linkedin.com/in/akhilshekkari/">LinkedIn</a></p>
    </footer>
</body>
</html>

