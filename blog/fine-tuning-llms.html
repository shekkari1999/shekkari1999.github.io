<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Understanding Fine-tuning in LLMs | Akhil Shekkari</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css">
    <link rel="stylesheet" href="../css/styles.css">
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
    <script>
        // Override Prism styles after it loads
        window.addEventListener('load', function() {
            document.querySelectorAll('pre, code').forEach(el => {
                el.style.fontSize = '11px';
                el.style.fontFamily = 'Consolas, Monaco, "Courier New", monospace';
            });
        });
    </script>
</head>
<body>
    <a href="../blogs.html" class="back-link">← Back to Blog</a>

    <article>
        <h1>Understanding Fine-tuning in Large Language Models</h1>
        
        <p class="blog-meta">March 15, 2024 · 20 min read</p>
        
        <p>
            Credit: This blog is my learnings from AI Engineering written by Chip Huyen.
            <a href="https://www.amazon.com/Engineering-Reliable-Systems-Chip-Huyen/dp/1098159276">Practical MLOps</a>
        </p>

        <h2>What is Fine-tuning?</h2>
        
        <p>
            Modifying the Parameter weights of the model to make it behave in a desired way. 
            Fine-tuning is often Applied after pretraining. 
            Fine Tuning improves the model's ability to output text in a certain way.
        </p>

        <div class="code-example">
# Before Fine-tuning
Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

# After Fine-tuning
Q: What is human life expectancy in the United States?
A: According to recent data from the CDC, the average life expectancy 
   in the United States is approximately 78 years, though this varies 
   significantly by demographic factors and has been impacted by 
   recent global events.</div>

        <h3>Benefits of Fine-tuning:</h3>
        <ul>
            <li>Improved accuracy on specific tasks</li>
            <li>Ability to adapt to different domains and languages</li>
        </ul>

        <h2>General guidelines before fine-tuning:</h2>

        <p>
            Always try out prompt Engineering and RAG before going for fine-tuning. Lets look at some 
            challenges if you want to fine-tuning.
        </p>

        <h3>1. Increases Memory Footprint</h3>
        
        <h3>2. Increases computation and cost</h3>
        
        <blockquote>
            "Fine-tuning is not just about improving performance—it's about finding the right balance 
            between computational resources, cost, and actual benefits to your specific use case."
        </blockquote>

        <p>
            The decision to fine-tune should be based on careful consideration of:
        </p>
        <ul>
            <li>Available computational resources</li>
            <li>Budget constraints</li>
            <li>Expected performance improvements</li>
            <li>Alternative approaches (like RAG)</li>
        </ul>

        <h3>Understanding the Backpropagation Process</h3>
        
        <div class="code-example">
<span class="comment">### Lets start back propagation</span>
<span class="keyword">def</span> <span class="function">relu_derivative</span>(x):
    <span class="keyword">return</span> <span class="builtin">np</span>.where(x > <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>)

m = Xtrain.shape[<span class="number">0</span>]

<span class="comment"># Backpropagation</span>
dZ2 = A2 - ytrain.reshape(<span class="number">-1</span>, <span class="number">1</span>)
dW2 = np.dot(A1.T, dZ2) / m
db2 = np.mean(dZ2, axis=<span class="number">0</span>, keepdims=<span class="keyword">True</span>)
dA1 = np.dot(dZ2, W2)
dZ1 = dA1 * relu_derivative(Z1)
dW1 = np.dot(Xtrain.T, dZ1) / m
db1 = np.mean(dZ1, axis=<span class="number">0</span>, keepdims=<span class="keyword">True</span>)

<span class="comment">### Lets print values</span>
<span class="comment">#print(dZ2, dW2, db2, dA1, dZ1, dW1, db1)</span></div>

        <p>
            This code demonstrates the backpropagation process in neural networks, 
            which is fundamental to the fine-tuning process.
        </p>
    </article>

    <footer>
        <p>© 2024 Akhil Shekkari · <a href="https://github.com/shekkari1999">GitHub</a></p>
    </footer>

    <script>
        // Initialize syntax highlighting
        Prism.highlightAll();
    </script>
</body>
</html> 